#source https://grafana.com/docs/alloy/latest/collect/logs-in-kubernetes/
apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-configmap
  namespace: alloy
data:
  values.yaml: |
    alloy:
      securityContext:
        privileged: true
        runAsUser: 0
      mounts:
        dockercontainers: true
        varlog: true
      listenAddr: 0.0.0.0
      listenPort: 12345
      configMap:
        create: true
        name: alloy-configmap
        content: |-
          // The prometheus.exporter.unix component exposes hardware and Linux kernel metrics. This is the primary component that you configure to collect your Linux system metrics.
          prometheus.exporter.unix "integrations_node_exporter" {
            disable_collectors = ["ipvs", "btrfs", "infiniband", "xfs", "zfs"]
            enable_collectors = ["meminfo"]

            filesystem {
              fs_types_exclude     = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|tmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
              mount_points_exclude = "^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)"
              mount_timeout        = "5s"
            }

            netclass {
              ignored_devices = "^(veth.*|cali.*|[a-f0-9]{15})$"
            }

            netdev {
              device_exclude = "^(veth.*|cali.*|[a-f0-9]{15})$"
            }
          }

          // There are two discovery.relabel components in this configuration. This discovery.relabel component replaces the instance and job labels that come in from the node_exporter with the hostname of the machine and a standard job name for all metrics.
          discovery.relabel "integrations_node_exporter" {
            targets = prometheus.exporter.unix.integrations_node_exporter.targets

            rule {
              target_label = "instance"
              replacement  = sys.env("HOSTNAME")
            }

            rule {
              target_label = "job"
              replacement = "integrations/node_exporter"
            }
          }


          // The prometheus.scrape component scrapes node_exporter metrics and forwards them to a receiver. In this example, the component requires the following arguments:
          prometheus.scrape "integrations_node_exporter" {
            scrape_interval = "15s"
            targets    = discovery.relabel.integrations_node_exporter.output
            forward_to = [prometheus.remote_write.mimir.receiver]
          }
          //k8 metrics scraping

          discovery.kubernetes "pods_metrics" {
            role = "pod"

            namespaces {
              own_namespace = false
              names = ["default","kube-system"]
            }

            selectors {
              role  = "pod"
            }
          }

          prometheus.scrape "pods" {
            scrape_interval = "15s"
            targets    = discovery.kubernetes.pods_metrics.targets
            forward_to = [prometheus.remote_write.mimir.receiver]
          }


          // writes metrics to mimir
          prometheus.remote_write "mimir" {
            endpoint {
            url = "http://mimir-mimir-gateway.mimir.svc.cluster.local/api/v1/push"
            }
          }

          //LOGS SCRAPING
          // This discovery.relabel component defines the relabeling rules for the systemd journal logs. In this example, this component requires the following arguments:
          discovery.relabel "logs_integrations_integrations_node_exporter_journal_scrape" {
            targets = []

            rule {
              source_labels = ["__journal__systemd_unit"]
              target_label  = "unit"
            }

            rule {
              source_labels = ["__journal__boot_id"]
              target_label  = "boot_id"
            }

            rule {
              source_labels = ["__journal__transport"]
              target_label  = "transport"
            }

            rule {
              source_labels = ["__journal_priority_keyword"]
              target_label  = "level"
            }
          }

          // The loki.source.journal component collects logs from the systemd journal and forwards them to a Loki receiver. In this example, the component requires the following arguments:
          loki.source.journal "logs_integrations_integrations_node_exporter_journal_scrape" {
            max_age       = "24h0m0s"
            relabel_rules = discovery.relabel.logs_integrations_integrations_node_exporter_journal_scrape.rules
            forward_to    = [loki.write.default.receiver]
          }

          // The local.file_match component discovers files on the local filesystem using glob patterns. In this example, the component requires the following arguments:
          local.file_match "logs_integrations_integrations_node_exporter_direct_scrape" {
            path_targets = [{
              __address__ = "localhost",
              __path__    = "/var/log/{syslog,messages,*.log}",
              instance    = sys.env("HOSTNAME"),
              job         = "integrations/node_exporter",
            }]
          }

          // The loki.source.file component reads log entries from files and forwards them to other Loki components. In this example, the component requires the following arguments:
          loki.source.file "logs_integrations_integrations_node_exporter_direct_scrape" {
            targets    = local.file_match.logs_integrations_integrations_node_exporter_direct_scrape.targets
            forward_to = [loki.write.default.receiver]
          }

          //k8 logs scraping
          // discovery.kubernetes allows you to find scrape targets from Kubernetes resources.
          // It watches cluster state and ensures targets are continually synced with what is currently running in your cluster.
          discovery.kubernetes "pod" {
            role = "pod"
            // Restrict to pods on the node to reduce cpu & memory usage
            selectors {
              role = "pod"
              field = "spec.nodeName=" + coalesce(sys.env("HOSTNAME"), constants.hostname)
            }
          }

          // discovery.relabel rewrites the label set of the input targets by applying one or more relabeling rules.
          // If no rules are defined, then the input targets are exported as-is.
          discovery.relabel "pod_logs" {
            targets = discovery.kubernetes.pod.targets

            // Label creation - "namespace" field from "__meta_kubernetes_namespace"
            rule {
              source_labels = ["__meta_kubernetes_namespace"]
              action = "replace"
              target_label = "namespace"
            }

            // Label creation - "pod" field from "__meta_kubernetes_pod_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_name"]
              action = "replace"
              target_label = "pod"
            }

            // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "container"
            }

            // Label creation -  "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
              action = "replace"
              target_label = "app"
            }

            // Label creation -  "job" field from "__meta_kubernetes_namespace" and "__meta_kubernetes_pod_container_name"
            // Concatenate values __meta_kubernetes_namespace/__meta_kubernetes_pod_container_name
            rule {
              source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "job"
              separator = "/"
              replacement = "$1"
            }

            // Label creation - "__path__" field from "__meta_kubernetes_pod_uid" and "__meta_kubernetes_pod_container_name"
            // Concatenate values __meta_kubernetes_pod_uid/__meta_kubernetes_pod_container_name.log
            rule {
              source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "__path__"
              separator = "/"
              replacement = "/var/log/pods/*$1/*.log"
            }

            // Label creation -  "container_runtime" field from "__meta_kubernetes_pod_container_id"
            rule {
              source_labels = ["__meta_kubernetes_pod_container_id"]
              action = "replace"
              target_label = "container_runtime"
              regex = "^(\\S+):\\/\\/.+$"
              replacement = "$1"
            }
          }

          // loki.source.kubernetes tails logs from Kubernetes containers using the Kubernetes API.
          loki.source.kubernetes "pod_logs" {
            targets    = discovery.relabel.pod_logs.output
            forward_to = [loki.process.pod_logs.receiver]
          }


          // loki.source.kubernetes_events tails events from the Kubernetes API and converts them
          // into log lines to forward to other Loki components.
          loki.source.kubernetes_events "cluster_events" {
            job_name   = "integrations/kubernetes/eventhandler"
            log_format = "logfmt"
            forward_to = [
              loki.process.cluster_events.receiver,
            ]
          }

          // loki.process receives log entries from other loki components, applies one or more processing stages,
          // and forwards the results to the list of receivers in the component's arguments.
          loki.process "cluster_events" {
            forward_to = [loki.write.default.receiver]

            stage.static_labels {
              values = {
                cluster = "default",
              }
            }

            stage.labels {
              values = {
                kubernetes_cluster_events = "job",
              }
            }
          }

          loki.process "pod_logs" {
            stage.static_labels {
                values = {
                  cluster = "default",
                }
            }

            forward_to = [loki.write.default.receiver]
          }

          // writes logs to loki
          loki.write "default" {
              endpoint {
                url = "http://loki-loki-gateway.loki.svc.cluster.local/loki/api/v1/push"
              }
            }
